"""Voice to MD ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""

import threading
from datetime import datetime
from pathlib import Path
from typing import Optional

import rumps
import librosa

from .config import OUTPUT_DIR, TEMP_AUDIO_PATH, SAMPLE_RATE
from .recorder import Recorder
from .transcriber import Transcriber, TranscriptionSegment
from .diarizer import Diarizer
from .progress_window import ProgressWindow


class VoiceToMdApp(rumps.App):
    """ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã«å¸¸é§ã™ã‚‹éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    def __init__(self) -> None:
        super().__init__(name="Voice to MD", title="ğŸ¤ Voice")
        self._recorder = Recorder()
        self._transcriber = Transcriber()
        self._diarizer = Diarizer()
        self._progress_window = ProgressWindow()
        self._is_recording = False
        self._is_processing = False

        rumps.notification(
            title="Voice to MD",
            subtitle="èµ·å‹•ã—ã¾ã—ãŸ",
            message="ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ã®ğŸ¤ Voiceã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³ã‚’é–‹å§‹",
        )

    @rumps.clicked("éŒ²éŸ³ é–‹å§‹/åœæ­¢")
    def toggle_recording(self, _: rumps.MenuItem) -> None:
        """éŒ²éŸ³ã®é–‹å§‹/åœæ­¢ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹"""
        if self._is_processing:
            return

        if not self._is_recording:
            self._start_recording()
        else:
            self._stop_recording()

    def _start_recording(self) -> None:
        """éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹"""
        try:
            self._recorder.start()
            self._is_recording = True
            self.title = "ğŸ”´ REC"
        except Exception as e:
            rumps.alert(
                title="ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼",
                message=(
                    f"éŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
                    f"ã‚¨ãƒ©ãƒ¼: {e}\n\n"
                    f"ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ > ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ > "
                    f"ãƒã‚¤ã‚¯ ã§ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨±å¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                ),
            )

    def _stop_recording(self) -> None:
        """éŒ²éŸ³ã‚’åœæ­¢ã—ã€å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹"""
        if self._is_processing:
            return

        self._is_processing = True
        self._is_recording = False
        self.title = "â³ ..."

        try:
            audio_path = self._recorder.stop()
            threading.Thread(
                target=self._process_audio,
                args=(audio_path,),
                daemon=True,
            ).start()
        except Exception as e:
            self._is_processing = False
            self.title = "ğŸ¤ Voice"
            rumps.alert(
                title="éŒ²éŸ³ã‚¨ãƒ©ãƒ¼",
                message=f"éŒ²éŸ³ã®åœæ­¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\n{e}",
            )

    def _process_audio(self, audio_path: str) -> None:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰"""
        try:
            self._progress_window.show()

            # éŒ²éŸ³æ™‚é–“ã‚’å–å¾—
            audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE, mono=True)
            duration_sec = len(audio) / sr
            duration_str = self._format_duration(duration_sec)

            # è©±è€…åˆ†é›¢
            self._progress_window.set_status("è©±è€…ã‚’åˆ†æä¸­...")
            try:
                speaker_segments = self._diarizer.diarize(audio_path)
                speaker_count = self._diarizer.get_speaker_count(speaker_segments)
            except Exception as e:
                print(f"è©±è€…åˆ†é›¢ã‚¨ãƒ©ãƒ¼: {e}")
                speaker_segments = [(0.0, duration_sec, "Speaker 1")]
                speaker_count = 1

            # æ–‡å­—èµ·ã“ã—
            self._progress_window.set_status("æ–‡å­—èµ·ã“ã—ä¸­...")
            try:
                transcription_segments = self._transcriber.transcribe(audio_path)
            except Exception as e:
                print(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
                transcription_segments = []

            # çµæœã‚’çµ±åˆ
            self._progress_window.set_status("çµæœã‚’çµ±åˆä¸­...")
            merged_segments = self._assign_speakers(
                transcription_segments, speaker_segments
            )

            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
            self._progress_window.set_status("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ä¸­...")
            now = datetime.now()
            filename = f"voice_{now.strftime('%Y%m%d_%H%M%S')}.md"
            output_path = OUTPUT_DIR / filename

            content = self._create_markdown_content(
                now, duration_str, speaker_count, merged_segments
            )
            self._save_markdown(output_path, content)

            self._progress_window.hide()

            rumps.notification(
                title="Voice to MD",
                subtitle="æ–‡å­—èµ·ã“ã—å®Œäº†",
                message=f"ä¿å­˜å…ˆ: {filename}",
            )

            self._cleanup_temp_file()

        except Exception as e:
            self._progress_window.hide()
            print(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            rumps.notification(
                title="å‡¦ç†ã‚¨ãƒ©ãƒ¼",
                subtitle="å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                message=str(e),
            )

        self.title = "ğŸ¤ Voice"
        self._is_processing = False

    def _assign_speakers(
        self,
        transcription_segments: list[TranscriptionSegment],
        speaker_segments: list[tuple[float, float, str]],
    ) -> list[dict]:
        """æ–‡å­—èµ·ã“ã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«è©±è€…ã‚’å‰²ã‚Šå½“ã¦ã‚‹"""
        result = []
        for trans_seg in transcription_segments:
            trans_start = trans_seg.start
            speaker = "Unknown"
            for spk_start, spk_end, spk_label in speaker_segments:
                if spk_start <= trans_start < spk_end:
                    speaker = spk_label
                    break
            result.append({
                "speaker": speaker,
                "start": trans_seg.start,
                "end": trans_seg.end,
                "text": trans_seg.text,
            })
        return result

    def _format_duration(self, seconds: float) -> str:
        """ç§’æ•°ã‚’ã€ŒXXåˆ†XXç§’ã€å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}åˆ†{secs:02d}ç§’"

    def _format_timestamp(self, seconds: float) -> str:
        """ç§’æ•°ã‚’ã€ŒMM:SSã€å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"

    def _create_markdown_content(
        self,
        timestamp: datetime,
        duration: str,
        speaker_count: int,
        segments: list[dict],
    ) -> str:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹"""
        lines = [
            f"# MTGãƒ¡ãƒ¢ - {timestamp.strftime('%Y/%m/%d %H:%M')}",
            "",
            f"éŒ²éŸ³æ™‚é–“: {duration}",
            f"æ¤œå‡ºã•ã‚ŒãŸè©±è€…æ•°: {speaker_count}",
            "",
            "---",
            "",
        ]

        for seg in segments:
            start_ts = self._format_timestamp(seg["start"])
            end_ts = self._format_timestamp(seg["end"])
            lines.append(f"**{seg['speaker']}** [{start_ts} - {end_ts}]")
            lines.append(seg["text"])
            lines.append("")

        return "\n".join(lines)

    def _save_markdown(self, path: Path, content: str) -> None:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹"""
        path.write_text(content, encoding="utf-8")

    def _cleanup_temp_file(self) -> None:
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹"""
        try:
            if TEMP_AUDIO_PATH.exists():
                TEMP_AUDIO_PATH.unlink()
        except OSError:
            pass

    @rumps.clicked("çµ‚äº†")
    def quit_app(self, _: rumps.MenuItem) -> None:
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã™ã‚‹"""
        rumps.quit_application()


if __name__ == "__main__":
    VoiceToMdApp().run()
